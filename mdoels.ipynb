{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Top 10 Model-Feature Combinations by Accuracy:\n",
      "                 Model                   Features  Accuracy\n",
      "99             XGBoost   [SFm, EDm, RSm, Asm, Km]      0.80\n",
      "103            XGBoost   [SFm, EDm, RSm, Rm, RTm]      0.75\n",
      "50                 SVM   [SFm, EDm, RSm, SEm, Km]      0.75\n",
      "47             XGBoost  [SFm, EDm, RSm, SEm, RTm]      0.75\n",
      "29   Gradient Boosting   [SFm, EDm, RSm, SEm, Em]      0.75\n",
      "15             XGBoost       [SFm, EDm, RSm, Asm]      0.75\n",
      "43             XGBoost   [SFm, EDm, RSm, SEm, Rm]      0.75\n",
      "49   Gradient Boosting   [SFm, EDm, RSm, SEm, Km]      0.75\n",
      "51             XGBoost   [SFm, EDm, RSm, SEm, Km]      0.75\n",
      "91             XGBoost   [SFm, EDm, RSm, Asm, Rm]      0.75\n"
     ]
    }
   ],
   "source": [
    "# ✅ Install necessary packages (uncomment the next line if running in a local environment without xgboost)\n",
    "# !pip install xgboost\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from itertools import combinations\n",
    "import warnings\n",
    "\n",
    "# ✅ Suppress warnings from libraries to clean output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load processed datasets\n",
    "train_df = pd.read_csv('Processed_TrainSet.csv')\n",
    "test_df = pd.read_csv('Processed_TestSet.csv')\n",
    "\n",
    "# ✅ Convert numeric labels in the training set to string labels for consistency\n",
    "label_mapping = {0: 'aggressive', 1: 'happy', 2: 'relaxed', 3: 'sad'}\n",
    "train_df['class'] = train_df['class'].map(label_mapping)\n",
    "\n",
    "# Separate features and target variables\n",
    "y_train = train_df['class']\n",
    "X_train = train_df.drop(columns=['class'])\n",
    "\n",
    "y_test = test_df['class']\n",
    "X_test = test_df.drop(columns=['class'])\n",
    "\n",
    "# ✅ Ensure consistent label encoding using the same encoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# ✅ Mandatory features always included in the feature set\n",
    "mandatory_features = [\"SFm\", \"EDm\", \"RSm\"]\n",
    "\n",
    "# ✅ Additional top features based on ANOVA F-Test (excluding mandatory ones)\n",
    "optional_features = [\"SEm\", \"Em\", \"RGm\", \"Asm\", \"Rm\", \"RTm\", \"Km\"]\n",
    "\n",
    "# ✅ Generate fewer combinations: select up to 2 additional features from the optional ones\n",
    "feature_combinations = [mandatory_features + list(combo) for combo in combinations(optional_features, 1)]\n",
    "feature_combinations += [mandatory_features + list(combo) for combo in combinations(optional_features, 2)]\n",
    "\n",
    "# ✅ Define models with tuned hyperparameters (removed use_label_encoder parameter from XGBoost)\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, max_depth=20, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42),\n",
    "    \"SVM\": SVC(C=10, kernel='rbf', random_state=42),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "# ✅ Evaluate models with the generated feature combinations\n",
    "results = []\n",
    "\n",
    "for feature_set in feature_combinations:\n",
    "    scaler = StandardScaler()\n",
    "    X_train_sub = scaler.fit_transform(X_train[list(feature_set)])\n",
    "    X_test_sub = scaler.transform(X_test[list(feature_set)])\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_sub, y_train_encoded)\n",
    "        predictions = model.predict(X_test_sub)\n",
    "\n",
    "        accuracy = accuracy_score(y_test_encoded, predictions)\n",
    "        results.append({\n",
    "            \"Model\": name,\n",
    "            \"Features\": feature_set,\n",
    "            \"Accuracy\": accuracy\n",
    "        })\n",
    "\n",
    "# ✅ Create and display a DataFrame of results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values(by=\"Accuracy\", ascending=False)\n",
    "\n",
    "# ✅ Print the top 10 feature-model combinations with the highest accuracy\n",
    "print(\"\\n✅ Top 10 Model-Feature Combinations by Accuracy:\")\n",
    "print(results_df.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
